---
title: "Untitled FRACTRAN Game"
tags: [allonge, mermaid, wip]
---

On April 8, 2020, [John Horton Conway] developed symptoms of COVID-19. On April 11, 2020, he succumbed to the disease.[^solveit][^princeton][^guardian][^nyt]

[John Horton Conway]: https://en.wikipedia.org/wiki/John_Horton_Conway
[^solveit]: ["Can you solve it? John Horton Conway, playful maths genius"](https://www.theguardian.com/science/2020/apr/20/can-you-solve-it-john-horton-conway-playful-maths-genius)
[^guardian]: [Obituary in The Guardian](https://www.theguardian.com/science/2020/apr/23/john-horton-conway-obituary) (paywall)
[^princeton]: [Mathematician John Horton Conway, a ‘magical genius’ known for inventing the ‘Game of Life,’ dies at age 82](https://www.princeton.edu/news/2020/04/14/mathematician-john-horton-conway-magical-genius-known-inventing-game-life-dies-age)
[^nyt]: [John Horton Conway, a ‘Magical Genius’ in Math, Dies at 82](https://www.nytimes.com/2020/04/15/technology/john-horton-conway-dead-coronavirus.html) (paywall)

Like so very, very many, I mourn Conway's passing, and also celebrate his life.

---

<center><img src="/assets/images/conway/john-conway-1993.jpg" alt="John Horton Conway in 1993"/></center>

---

## Prelude

*This is another prelude long on nostalgia, and short on programming. If that does not interest you, feel free to skip straight to* [FRACTRAN](#fractran).

Conway touched my own life from early days. As I described in [The Eight Queens Problem... and Raganwald's Unexpected Nostalgia](https://raganwald.com/2018/08/03/eight-queens.html):

*My mother had sent me to a day camp for gifted kids once, and it was organized like a university. The "students" self-selected electives, and I picked one called **Whodunnit**. It turned out to be a half-day exercise in puzzles and games, and I was hooked.*

*Where else would I learn about playing tic-tac-toe in a hypercube? Or about liars and truth-tellers? Or, as it happened, about [Martin Gardner][mg]? I suspect the entire material was lifted from his collections of columns, and that suited me down to the ground.*

[mg]: https://en.wikipedia.org/wiki/Martin_Gardner

One of the things we talked about in "Whodunnit" was [Conway's Game of Life][GoL]. I recall hearing about it there, but I also don't recall playing with it much. There was a lot going on, and it's entirely possible that I was too busy falling in love with Raymond Sullyan at age [eleven] to have curiosity left over for John Conway.[^HL][^TSL][^CoL]

[GoL]: https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life
[^CoL]: [Cafe au Life](https://github.com/raganwald/cafeaulife), an implementation of HashLife in CoffeeScript
[^HL]: [HashLife in the Browser](https://github.com/raganwald/hashlife)
[^TSL]: [Time, Space, and Life As We Know It](https://raganwald.com/2017/01/12/time-space-life-as-we-know-it.html)
[eleven]: https://www.youtube.com/watch?v=MNuFcIRlwdc

---

[![Hashlife](/assets/images/conway/hashlife.png)](http://raganwald.com/hashlife*/)
<center><a href="http://raganwald.com/hashlife/">An infinitely scrolling implementation of Conway's Game of Life</a></center>

---

I went on to rediscover Conway's Game of Life several times in my life. We talked of in university. And years later, I read William Poundstone's [The Recursive Universe: Cosmic Complexity and the Limits of Scientific Knowledge][ru], and it literally blew my mind:

[ru]: https://www.amazon.com/gp/product/0809252023/ref=as_li_ss_tl?ie=UTF8&linkCode=ll1&tag=raganwald001-20&linkId=2676ba561595f3a279e159b2b0be475b&language=en_US

Along the way, I learned a little about Game Theory. I loved games of all kinds, and I think I spotted [Games of Strategy: Theory and Applications][GoS] in a library and picked it up, thinking it would help my Backgammon.

[GoS]: https://www.rand.org/pubs/commercial_books/CB149-1.html

That led me to Conway's [On Numbers and Games][onag], and via parallel paths, to [Surreal Numbers]. Like the Game of Life, Surreal Numbers keep popping up unexpectedly, reigniting my interest in how the way we represent data, affords or hinders working with that data.

The subject of numbers and representation leads us to [FRACTRAN].[^elegance][^horton]

[onag]: https://en.wikipedia.org/wiki/On_Numbers_and_Games
[Surreal Numbers]: https://en.wikipedia.org/wiki/Surreal_number
[^elegance]: [Elegance and the Surreals](https://raganwald.com/2009/03/07/elegance-and-the-surreals.html)
[^horton]: [A Surreal Encounter with a Winged Elephant](https://raganwald.com/enchanted-forest/horton.html)
[FRACTRAN]: https://en.wikipedia.org/wiki/FRACTRAN

---

<a name="fractran"/>[![Only FRACTRAN has these star qualities](/assets/images/conway/fractran-star-qualities.png)][FRACTRAN]

---

## FRACTRAN

In 1987, Conway contributed _FRACTRAN: A SIMPLE UNIVERSAL PROGRAMMING LANGUAGE FOR ARITHMETIC_ to a special workshop on problems in communication and computation conducted in the summers of 1984 and 1985 in Morristown, New Jersey, and the summer of 1986 in Palo Alto. California. FRACTRAN itself was not an important open problem in the field, but as the editors of the published papers noted:

_Perhaps the most entertaining of all the contributions is Conway's fascinating article on FRACTRAN, a strange collection of numbers, which when operated on in a simple way. yield all possible computations. We begin with his article._
--Thomas M. Cover & B. Gotinath, "Open Problems in Communication & Computation"[^scihub]

[^scihub]: "Open Problems in Communication & Computation" is available on SciHub, or by paying rent to Springer-Verlag. I chose to use SciHub and to simultaneously purchase a used copy of the book online. I don't know how long we'll still be able to buy used books, but I'm taking full advantage of the privilege while we're still permitted to do so.

### our first fractran program

As Wikipedia notes, a FRACTRAN program is an ordered list of positive fractions together with an initial positive integer input *n*. The program is run by updating the integer *n* as follows:

1. for the first fraction *f* in the list for which *nf* is an integer, replace *n* by *nf*
2. repeat this rule until no fraction in the list produces an integer when multiplied by *n*, then halt.

For example, this is a FRACTRAN program for computing any Fibonacci number: `17/65`, `133/34`, `17/19`, `23/17`, `2233/69`, `23/29`, `31/23`, `74/341`, `31/37`, `41/31`, `129/287`, `41/43`, `13/41`, `1/13`, `1/3`.[^snark]

[^snark]: Feel free to use FRACTRAN to ace the programming interview when somene asks for a program to compute `fib(n)`.

All FRACTRAN programs also start with an initial value for *n*. That value is sometimes a constant, and sometimes provided by the user. When it's provided by the user, there is sometimes a need to prepare *n* to make it usable.

In this program's case, to compute `fib(x)` for some value of *x*, we compute `n = 78 * 5^(x - 1)`.

Let's use this program to compute `fib(7)`. We start with `n = 78 * 5^(7-1)`, which is **1,218,750**. We'll follow along for a while to get the feel for what happens:[^debug-fib]

[^debug-fib]: The complete debug output is in [this gist](https://gist.github.com/raganwald/57e9ebf26e3cd2d07aa014e79c1e9748#file-out-md).

- The first fraction in the program is 17/65. 1,218,750 multiplied by 17/65 is 318,750, so we replace 1,218,750 with 318,750 and begin again.
- The first fraction in the program is 17/65. 318,750 leaves a remainder when divided by 65, so we move on.
- The next fraction in the program is 133/34. 318,750 multiplied by 133/34 is 1,246,875, so we replace 318,750 with 1,246,875 and begin again.

We leave it to run for a very long time, and then we see:

- The first fraction in the program is 13/41. 24,576 leaves a remainder when divided by 41, so we move on.
- The first fraction in the program is 1/13. 24,576 leaves a remainder when divided by 13, so we move on.
- The first fraction in the program is 1/3. 24,576 multiplied by 1/3 is 8,192, so we replace 24,576 with 8,192 and begin again.

8,192 is an important number, because *none* of the divisors divide evenly into 8,192. So we see

- The first fraction in the program is 17/65. 8,192 leaves a remainder when divided by 65, so we move on.
- The next fraction in the program is 133/34. 8,192 leaves a remainder when divided by 34, so we move on.
- The next fraction in the program is 17/19. 8,192 leaves a remainder when divided by 19, so we move on.

...

- The next fraction in the program is 13/41. 8,192 leaves a remainder when divided by 41, so we move on.
- The next fraction in the program is 1/13. 8,192 leaves a remainder when divided by 13, so we move on.
- The next fraction in the program is 1/3. 8,192 leaves a remainder when divided by 3, so we move on. None of the demoninators in the program divide evenly into 8,192, so the program halts.

All FRACTRAN programs produce a series of values for *n*, and the result we want must be extracted from them. For our Fibonacci program, the values begin with `1,218,750`, `318,750`, `1,246,875`, and `1,115,625`, and then end with `221,184`, `73,728`, `24,576`, and `8,192`.[^n-fib]

[^n-fib]: The complete list of values of *n* is in [this gist](https://gist.github.com/raganwald/57e9ebf26e3cd2d07aa014e79c1e9748#file-values-of-n-txt).

In the case of Fibonacci, the result we want is the `log2` of the last value for *n*. The last value of *n* is 8,192, and `log2(8,192)` is **13**, the answer we want. The 7th Fibonacci number is 13.

We have now seen the three elements that every FRACTRAN program has:

1. The program itself, a finite list of fractions. This program's list is `17/65`, `133/34`, `17/19`, `23/17`, `2233/69`, `23/29`, `31/23`, `74/341`, `31/37`, `41/31`, `129/287`, `41/43`, `13/41`, `1/13`, and `1/3`.
2. An initial value of *n*. This may be a constant, it may be a user-supplied value, or it may be a transformation of a user-defined value. This program's transformation can be expressed in JavaScript as `n => 78 * Math.pow(5, n-1)`.
3. A transformation from the values of *n* into the result we want, encoded the way we want it. In our case, it is something like `values => log2(last(values))` .

### writing a fractran-based fibonacci function in javascript

Writing a FRACTRAN interpreter is very easy. Let's begin by writing a JavaScript Fibonacci function that uses our FRACTRAN program for its implementation. The main thing we'll need to watch out for is that that values of *n* can grow very, very large, so we will want to use big integers, aka "BigInts."[^bigint]

[^bigint]: `BigInt` is slated to enter JavaScript formally in ES2020. Most of the code in this blog is deliberately as old as possible, however exceptions are justified when the feature greatly simplifies the code by removing accidental complexity, and doesn't affect the central idea of the code itself.<br/><br/>In this case, using a third-party BigInt library or rolling our own big integer implementation would obfuscate the central idea of the code.

One consequence of working with big integers is that many of the things we depend on for numbers no longer work. For example, `Math.log2(8192) => 13`, but `math.log2(8192n) => TypeError: Cannot convert a BigInt value to a number`. We'll have to write our own `log2` function.

The same goes for `Math.pow`, we'll have to write our own. Feel free to use these implementations if you like:

```javascript
// Any sufficiently complicated function that loops, contains an ad hoc,
// informally-specified, bug-ridden, slow implementation of
// half of Linear Recursion
const log2 = (n) => {
  let result = 0n;

  while (true) {
    // degenerate condition
    if (n === 1n) break;

    // termination conditions
    if (n % 2n === 1n) return;
    if (n < 1n) return;

    //divide and conquer
    ++result;
    n = n / 2n;
  }

  return result;
}

const pow = (base, exponent) => {
  if (exponent < 0n) return;

  let result = 1n;

  while (exponent-- > 0n) result = result * base;

  return result;
}
```

Now go ahead and write your own implementation. Ignore the code below until you've written your own.

```javascript
// uses log2 and pow from above to formulate the seed and decipher the result

const fib = (x) => {
  const program = (
    '17/65, 133/34, 17/19, 23/17, 2233/69, 23/29, 31/23, 74/341,' +
    ' 31/37, 41/31, 129/287, 41/43, 13/41, 1/13, 1/3'
  ).split(', ').map(f => f.split('/').map(n => BigInt(n)));

  let n = 78n * pow(5n, BigInt(x) - 1n);

  program_start: while (true) {
    for (const [numerator, denominator] of program) {
      if (n % denominator === 0n) {
        n = (n * numerator) / denominator;
        continue program_start;
      }
    }
    break;
  }

  return log2(n);
};

fib(7)
  //=> 13
```

This is very cool. The FRACTRAN program is very small and ridiculously simple: It's just fractions. And the central FRACTRAN interpreter is also very small: It's literally a for loop inside a while loop, and the while loop (along with a break statement) could have been avoided if JavaScript supported GOTO.[^chch]

[^chch]: Before anybody [quotes Djikstra](/assets/media/Dijkstra68.pdf), remember that ["Considered Harmful" Essays Considered Harmful](https://meyerweb.com/eric/comment/chech.html)

For all its apparent elegance, FRACTRAN appears at first glance to be inscrutable. Is it one of those languages that is neither good for reading nor writing? Or is there a method to the madness of writing a program by composing a list of fractions?

To answer this question, we must first consider the work of another great mind that we have lost, [Marvin Minsky].

[Marvin Minsky]: http://web.media.mit.edu/~minsky/

---

[![Marvin Minsky](/assets/images/conway/marvin-minsky.jpg)][Marvin Minsky]

---

## Marvin Minsky's Magnificent Machines

### another nostalgic diversion

In September of 1987, [Stewart Brand] published [The Media Lab: Inventing the Future at M.I.T.][The Media Lab]. To say that the book affected me does not do its impact justice. Like many business and technical hagiographies, it was breathless in its admiration for what M.I.T.--and director Nicholas Negroponte--were trying to do.

[Stewart Brand]: http://sb.longnow.org/
[The Media Lab]: https://www.amazon.com/Media-Lab-Inventing-Future-M-I-T/dp/0670814423/ref=as_li_ss_tl?ie=UTF8&linkCode=ll1&tag=raganwald001-20&linkId=e5653e0666603d4426dc84ed2719d0a8&language=en_US

It was also highly revealing: Brand described in detail how the Media Lab was funded by its corporate sponsors, and exactly how the funding model drove research. Their motto was, "Demo or Die," which meant that the money went to the people who could not only wow their peers, but also provide the stage-magic that would open the wallets of their corporate sponsors.

I was working in technology Enterprise Sales at the time, and keenly understood that while it's really difficult to sell sizzle without steak, it's equally improbable to secure the sale when you have perfectly good steak, but no sizzle.[^gatekeepers]

[^gatekeepers]: There is a persistant myth in software that Enterprise Technology Sales are conducted on the golf course, and that the sales team who spends the most on steak and bourbon wins the deal no matter how crap-tastic their proposal.<br/><br/>People promulgating this myth greatly underestimate the number of individuals in any non-trivial organization who lay in wait for proposals, ready to make their own reputations by pointing out the flaws in every proposed adoption project.

One of the figures mentioned in The Meda Lab was [Marvin Minsky]. Minsky was considered a giant in Artificial Intelligence, and Artificial Intelligence was the [tulip mania] of the day. History would show that as the book was released, AI funding was starting another of its cyclical collapses, but as I read the book, the magazines and book shelves were groaning under the weight of breathless prose and utopian visions.

[tulip mania]: https://en.wikipedia.org/wiki/Tulip_mania

---

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/-Hx8RixhoOM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center>

---

In 1985, Minsky had published [The Society of Mind], and I bought it on the strength of reading about Minsky in The Media Lab. In 1994, a company called Voyager published a [CD-ROM version of The Society of Mind][CDSoM] that I "played" using one of Apple's quirkier products, a CD-ROM reader and audio-CD player they borrowed from Phillips and branded as [PowerCD].

[The Society of Mind]: https://www.amazon.com/exec/obidos/ISBN=0671657135/marvinminskyA/ref=as_li_ss_tl?ie=UTF8&linkCode=ll1&tag=raganwald001-20&linkId=cbacf6f35f9fee30f018335fa1518663&language=en_US
[CDSoM]: http://web.media.mit.edu/~minsky/Voyager.html
[PowerCD]: https://en.wikipedia.org/wiki/PowerCD

One of the features of the CD-ROM was an interactive tour of Minsky's office. I still vividly recall his discussion of a mirror he had hanging on the wall, and his mention that Feynman had written an [entire book][QED] devoted to explaining just one thing: How light **actually** reflects off a mirror, and that in this book, he explains why all of the things non-specialists believe about light and reflection are actually false.

[QED]: https://en.wikipedia.org/wiki/QED:_The_Strange_Theory_of_Light_and_Matter "QED: The Strange Theory of Light and Matter"

Like Feynman and Conway, Minsky had a talent for explaining challenging ideas. And also like Feynman and Conway, he had made enormous contributions to the progress of human knowledge. One of his areas of research was in computability, and specifically, the study of a certain class of idealized computing machines that are now named *Minsky Machines* in his honour.[^mm-esolang][^mm-wiki]

[^mm-esolang]: [Minsky Machines on esoloangs.org](https://esolangs.org/wiki/Minsky_machine)
[^mm-wiki]: [Minsky Machines on Wikipedia](https://en.wikipedia.org/wiki/Register_machine#Minsky,_Melzak-Lambek_and_Shepherdson–Sturgis_models_"cut_the_tape"_into_many)

### minsky machines and turing machines

A *Minksy Machine* is an idealized machine that has been proven to be computationally universal. Minsky Machines are part of the family of idealized machines called [Register Machines].

[Register Machines]: https://en.wikipedia.org/wiki/Register_machine

A Minksky Machine is a little like a [Turing Machine]. Like a Turing Machine, a Minsky Machine has a finite number of states. However instead of one tape that stretches to infinity in one or both directions, Minsky machines have a finite number of tapes, each of which stretches to infinity in only one direction.

Like a Turing Machine, a Minsky Machine scans what is under its tape-head, and based on what it matches, can move the tape-head and change to a different state. Unlike a Turing machine, Minsky Machines have a tape-head for each tape, and therefore it's "rules" for each state can involve testing one or more of the symbols under its tape-heads.

Also unlike a Turing Machine, a Minksy Machine cannot write anything on the tape. Minksky Machines begin with a single symbol at the beginning of each tape, and the rest of the each tap is blank.

Like a Turing Machine, when a Minsky Machine matches a particular set of symbols under its tape-heads, the Minksy Machine can move the tape-head one square in either direction. Unlike a Turing Machine, a Minsky Machine can move one or more of its tape-heads.

The net effect of these design choices is that a Minksky Machine can store an arbitrary amount of state, just like a Turing Machine, but it stores that state by having each tape-head be an arbitrary distance from the beginning mark. Furthermore, the only real test it can perform for each tape is whether the tape-head is at position zero or not, so the only way to test whether the tape-head is a certain distance from the beginning or not is to move it towards the beginning and see if it runs out of tape or not.

[Turing Machine]: https://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/turing-machine/one.html "What is a Turing Machine?"

---

![Multi Tape](/assets/images/conway/multi-tape.jpeg)

<center><i>An illustration of a multi-tape machine</i></center>

---

### a simple minsky machine

Let's write a program using a Minsky Machine. There are various formulations of Minsky Machines, but the one we will use works like this:

1. Our machine will have a finte number of states, denoted with consecutive positive integers, i.e. 1, 2, 3, ...
2. Each state will have an finite and ordered list of rules.
3. Each rule will be expressed as "Do this, provided that." Thus, they will have two clauses: An action clause, and a guard clause.
4. The action clause shall consist of a set of tape-heads to move forward, i.e. away from the end, and a positive integer for each tape-head stating how many squares to move. We shall note these as tuples of (tape-identifier, squares-to-move-forward). The action clause is an unordered set of such tuples, with no two tuples in the same rule sharing the same tape-head. The action clause will also include a positive integer indicating the next state to enter.
5. The guard clause shall consist of a set of tape-heads to move backwards, i.e. towards the end, and a positive integer stating how many squares to move towards the beginning. As with the action clause, no two guard clauses in the same rule can share the same tape-head.
6. Because no two clauses in the same rule can share the same tape-head, it follows that no one rule can both test a tape-head in the guard clause and simultaneously move a tape-head in the action clause.

Our Minsky Machine is initialized with the tape-heads being placed in a specific set of positions, so in addition to listing the states and rules therein, the description of a Minsky machine will also include instructions for setting up the initial states.

Our machine will always start in state 1.

We run our machine by scanning the rules within the current state in order. For each rule, we check its guard clause. If it is possible to move all of the tape-heads in the guard clause towards the end, the rule "fires" and the action clause is executed by moving all of the tape-heads listed away from the end, and then changing to the next state listed.

If a rule's guard clause cannot perform all of the required movement of tape-heads towards the beginning, it fails, and the tape-heads are not disturbed. We then move on and try the next rule in that state's list, and the next, and so forth.

If any rule within a state succeeds, we execute it and move to the next state, ignoring the rest of the rules in the existing state. If all of the rules in the current state fail, the machine halts. It follows, trivially, that if the machine enters a state without any rules, it must necessarily halt.

If the machine attempts to transition to an undefined state, it also halts. An explicit transition to state 0, therefore, is the well-formed way to explicitly halt the machine.

### a one-state minsky machine that adds two numbers

Here's a diagram of a program that adds two numbers positive numbers, which we shall call `a` and `b`. It has three tapes, 1, 2, and 3. To set the machine up, we place tape-head 1 at the beginning of its tape, tape-head 2 `a` squares forward, and we place tape-head 3 `b` squares forward. When the machine halts, tape-head 1 will be `a + b` squares forward, while tape-heads 2 and 3 will be at the beginning:

<div class="mermaid">
  stateDiagram
    [*] --> One
    One --> One: (1,1)/(2,1)|(1,1)/(3,1)
    One --> [*]
</div>

Our notation for rules is very simple. In each state, there is a `|`-separated list of rules. Our machine only has one state, `One`, and it has two rules: `(1,1)/(2,1)→One` and `(1,1)/(3,1)→One`. We can omit the state when a rule does not cause the machine to change states, therefore our notation is simplified to `(1,1)/(2,1)|(1,1)/(3,1)` for the entire machine.

Each rule has an action clause of zero or more tuples of the form `(t,s)`, where `t` identifies the tape-head, and `s` identifies the number of squares to move forward, followed by a `/`, followed by a guard clause of zero or more tuples of the form `(t,s)`, where `t` again specifies the tape-head, and `s` specifies the number of squares to move back towards the beginning if possible.

We can use it to add the numbers 2+2, and we'll see if it comes up with 4. There is a more compact notation, but we'll be extravagant and write out the state of our machine like this:

```
1: *
2: ..*
3: ..*
```

This shows that tape-head 1 is at the beginning, while tape-heads 2 and 3 are two squares forward, the beginning conditions for adding 2 and 2.

Our machine begins in state `One` (it's the only state this machine has). The first rule is `(1,1)/(2,1)`. It checks to see if tape-head 2 can move one square towards the beginning. It can, therefore it also executes the action of moving tape-head 1 one square away from the beginning. It states in state `One`, and now the tape-head positions are:

```
1: .*
2: .*
3: ..*
```

Once gain, it consults its rules, and the first rule fires again, producing this state:

```
1: ..*
2: *
3: ..*
```

The third time through, rule 1 fails to fire because its guard clause `/(2,1)` fails. It remains in its only state, and checks the second rule, `(1,1)/(3,1)`. Tape-head 3 can be moved one square towards the beginning, and it does so while moving tape-head 1 away from the beginning:

```
1: ...*
2: *
3: .*
```

Once gain, it consults its rules, and the second rule fires again, producing this state:

```
1: ....*
2: *
3: *
```

The last time through, neither rule can fire, because neither tape-head 2 or tape-head 3 can move one square towards the beginning, so the machine halts. As we desired, tape-head 1 is now four squares forward of the beginning, so our machine has added 2 and 2 to produce 4.

### the minsky multiplication machine

This is a diagram of a three-state Minsky Machine that multiplies two numbers:

<div class="mermaid">
  stateDiagram
    [*] --> One
    One--> One: (1,0)/(3,1)
    One --> Two: (1,0)/(2,1)
    Two --> Two: (4,1)/(3,1)
    Two --> Three: (1,0)/(1,0)
    Three --> Three: (1,1)(3,1)/(4,1)
    Three --> One: (1,0)/(1,0)→1
    One --> [*]
</div>

The diagram doesn't do it justice without understanding the order of the rules within each state, so let's move to a text format. Elaborating on our notation somewhat by introducing the notion of separating states with `;`, our minsky multiplication machine can be written as:

```
(1,0)/(2,1)→2|(1,0)/(3,1);
(1,1)(4,1)/(3,1)|(1,0)/(1,0)→3;
(3,1)/(4,1)|(1,0)/(1,0)→1
```

As with the addition machine, we give it three tapes: A result tape that must be empty, and two multiplicand tapes, with the tape-head advanced by the value of the multiplicand. We also supply a fourth tape to use as a temporary variable. Thus, to multiply 3 and 39, we set the machine's tapes to `0, 3, 39, 0`.

The operation of the machine is easy to describe at a high level. There's one idiom that we first introduce: `(1,0)` is a `NOOP` clause. If used as a guard clause, it always succeeds because every tape-head is always in a position where it can move zero squares backwards. And if used as an action clause, it does nothing because it moves the tape-head zero squares forward. And a clause like `(1,0)/(0,1)→1` is a Minsky Machine's way of writing `GOTO`: It always succeeds, doesn't change the machine's state, and changes to state `1`.

The initial state (`1`) has two rules:

1. `(1,0)/(2,1)→2`, which decrements tape 2 and then changes to state 2, followed by;
2. `(1,0)/(3,1)`, which decrements tape 3 and remains in state 1.

The net effect of these two rules is that whenever the machine is in state 1, it tries to decrement tape 2 and move to state 2. If that fails, it tries to decrement tape 3 and remain in state 1. When it decrements tape 3 and remains in state 1, it clearly will do it again, and again, and again until it can decrement state 3 no more, at which point it will fail both of its rules, and halt.

The second state's two rules are:

1. `(1,1)(4,1)/(3,1)`, which increments tapes 1 and 4, decrements tape 3, and stays in state 2, followed by;
2. `(1,0)/(1,0)→3` which is a simple `GOTO 3`.

The net effect of state 2's rules is simply to add the value of tape 3 to whatever is in tape 1, while simultaneously making a copy of tape 3 in tape 4 (because in our Minsky Machines, successfully reading a value also consumes that value.

The third states two rules are:

1. `(4,1)/(3,1)`, which copies tape 3's original value back to tape 3 from tape 4, followed by;
2. `(1,0)/(1,0)→1` which is a simple `GOTO 3`.

The net effect of the third rule is to restore tape 3. Since this machine copies the value of tape 3 to tape 1 once for every square of tape 2, the net effect is to multiply tapes 2 and 3.

### implementing minsky machines

Manually simulating ideal computing machines loses its lustre once you've manually verified that `3 * 13 = 39`. Without peeking ahead, try writing an interpreter that can parse our notation and output the result.

For example, we'd like to write:

```javascript
const minsky = (program, ...tapes) => {
  // ...
};

minsky(
  '(1,1)/(2,1)|(1,1)/(3,1)',
  0, 2, 3
)
  //=> [5, 0, 0]

minsky(
  '(1,0)/(2,1)→2|(1,0)/(3,1);'      +
  '(1,1)(4,1)/(3,1)|(1,0)/(1,0)→3;' +
  '(3,1)/(4,1)|(1,0)/(1,0)→1',
  0, 3, 13, 0
)
  //=> [39, 0, 0, 0]
```

No peeking until you've tried it yourself!

```javascript
const parse = (program) => {
  const parseProgram = program => program.split(/\s*;\s*/).map(s => s.trim());
const parseState = state => state.split(/\s*\|\s*/).map(s => s.trim());
  const parseRule = (rule, stateIndex) => {
    const [clauses, nextState] = rule.includes('→') ? rule.split(/\s*→\s*/).map(s => s.trim()) : [rule.trim(), stateIndex + 1]

    return [clauses, typeof nextState === 'string' ? parseInt(nextState, 10) : nextState];
  };
  const parseClauses = clauses => clauses.split(/\s*\/\s*/).map(s => s.trim());
  const parseClause = clause => {
    if (clause === '') return [];

    const strippedClause = clause.substring(1, clause.length - 1); // strip opening and closing ()
    const pairs = strippedClause.split(/\)\s*\(/).map(s => s.trim());

    return pairs.map(p => p.split(/\s*,\s*/).map(s => parseInt(s, 10)));
  };

  return [[]].concat(
    parseProgram(program).map(
      (state, stateIndex) => parseState(state).map(
        rule => {
          const [_clauses, nextState] = parseRule(rule, stateIndex);
          const clauses = parseClauses(_clauses).map(parseClause);

          return clauses.concat([nextState]);
        }
      )
    )
  );
}

const interpret = (parsed, input = []) => {
  const tapes = ['ANCHOR', ...input]; // fake 1-indexing

  let stateIndex = 1;

  run: while (stateIndex > 0 && stateIndex < parsed.length) {
    const rules = parsed[stateIndex];
    for (const [actionClauses, guardClauses, nextState] of rules) {
      if (guardClauses.some(
        ([tapeIndex, squares]) => tapes[tapeIndex] === undefined || tapes[tapeIndex] < squares
      )) continue;
      for (const [tapeIndex, squares] of guardClauses) {
        tapes[tapeIndex] = tapes[tapeIndex] - squares;
      }
      for (const [tapeIndex, squares] of actionClauses) {
        tapes[tapeIndex] = (tapes[tapeIndex] || 0) + squares;
      }
      stateIndex = nextState;
      continue run;
    }
    break;
  }

  const output = tapes.slice(1); // unfake 1-indexing

  return output;
}

const minsky = (program, ...tapes) => interpret(parse(program), tapes);
```

Now that we have a machine to emulate our machines, we can explore an interesting idea.

---

![Marvellous Spatuletail Dubi Shapir/ABCbirds.Org ](/assets/images/conway/Marvellous-Spatuletail-Dubi-Shapiro-ABCbirds.org_.jpg)

<center><i>Marvellous Spatuletails are endemic to Peru. (Dubi Shapiro/ABCbirds.org)</i></center>

---

## Marvellous Minsky Machines

Here is another Minsky Machine that multiplies two numbers, we shall call it the **marvellous multiplier**:

```
(1,1)(4,1)(6,1)/(3,1)(5,1) |
(7,1)/(5,1)                |
(3,1)(8,1)/(4,1)(7,1)      |
(1,0)/(7,1)                |
(5,1)/(6,1)                |
(7,1)/(8,1)                |
(5,1)/(2,1)                |
(1,0)/(3,1)
```

Although we've broken its rules into separate lines for readability, it is a one-state multiplier. Our previous multiplier needed three states:

```
(1,0)/(2,1)→2|(1,0)/(3,1)      ;
(1,1)(4,1)/(3,1)|(1,0)/(1,0)→3 ;
(3,1)/(4,1)|(1,0)/(1,0)→1
```

How does our marvellous multiplier work without the other states?

The not-very-secret secret is that in addition to the four tapes our multiplier needs to do its main business, we've added four more tapes: 5, 6, 7, and 8. We only ever set them to 1 or zero, so they act like flags that emulate four additional states.

Let's analyze this, state-by state. The first state of the original multiplier had two rules:

```
(1,0)/(2,1)→2 |
(1,0)/(3,1)
````

These two rules are the _last_ rules of the marvellous multiplier:

```
(5,1)/(2,1) |
(1,0)/(3,1)
```

Why are they the last rules? Since we are using tapes 5, 6, 7, and 8 to emulate other states, every rule that comes before these rules is guarded by `(5,1)`, `(6,1)`, `(7,1)`, or `(8,1)`. Thus , these rules only come into play if _none_ of these state-emulation tapes.

But what about the rules themselves? The second rule, `(1,0)/(3,1)`, is the same thing we already have, it decrements tape 3 and remains in the only state, thus it will clear tape 3 and then the entire program will halt, just as with the original.

The first of our original rules is different. Instead of `(1,0)/(2,1)→2`, we have `(5,1)/(2,1)`. Instead of setting the next state to 2, we increment tape 5.

That leads us to the original state 2:

```
(1,1)(4,1)/(3,1) |
(1,0)/(1,0)→3
```

And our marvellous machine's equivalent:

```
(1,1)(4,1)(6,1)/(3,1)(5,1) |
(7,1)/(5,1)
```

Both of these rules are guarded by `(5,1)`, which matches what we saw from the rule in the original state 1: incrementing tape 5 makes this machine act like it's in the original state 2.

The first rule of the original machine incremented tapes 1 and 4, decremented tape 3, and remained in state 2. Our new rule also increments tapes 1 and 4, and decrements tape 3. And we know that we have to have it get back to the emulated state 2 by incrementing tape 5. But it is forbidden to both decrement and increment the same tape in our Minsky Machines, so it increments tape 6 instead.

How does that get us to incrementing tape 5? Look further down, and we find this rule:

```
(5,1)/(6,1)
```

If the  marvellous multiplier finds itself with tape 6 incremented, it turns around and increments tape 5. Thus, incrementing tape 6 is an indirect way of incrementing tape 5, and that's whaat our machine does when it is already decrementing tape 5.

We already know why the second of our original rules for state 2, `(1,0)/(1,0)→3`, becomes `(7,1)/(5,1)` in the marvellous multiplier. Instead of always matching with a `(1,0)` guard, it only matches when tape 5 is incremented, because tape 5 emulates state 2. And instead of setting having a NOOP action with `(1,0)` and setting the next state to 3, it increments tape 7 because tape 7 emulates state 3.

We now know everything we need to know to interpret how the marvellous machine's `(3,1)(8,1)/(4,1)(7,1)|(1,0)/(7,1)` emulates the original's `(3,1)/(4,1)|(1,0)/(1,0)→1`, and why there's a `(7,1)/(8,1)` rule added to support it.

The marvellous multiplier illustrates a key property of these Minsky Machines: **For every Minsky Machine with two or more states, there exists an equivalent Marvellous Minsky Machine with just one state, but more tapes.**[^even-more-marvellous]

[^even-more-marvellous]: Even more marvellously, for every Minsky Machine with two or more tapes, there exists an equivalent Minksy Machine with just one tape, but more states. But we are getting ahead of ourselves.

### an algorithm to derive a marvellous minsky machine from any minsky machine

From our exploration of the marvellous multiplier, we picked upa few tricks for emulating states with additional tapes:

1. Place the original state 1 last;
2. For each state beyond 1, set up two additional tapes, `stateTape` and `stateTapePrime`;
3. Guard the rules of the original state with `stateTape`;
4. For rules outside the state that transfer to the state, remove the nextState and add an action to increment `stateTape`.
5. For rules of the original state that remain in the state, add an action to increment `stateTapePrime`;
6. Add a rule to transfer from `stateTapePrime` to `stateTape`.

This can, of course, be automated. If you're keen, have a go at it before reading this example. If you're **really** keen, see if you can devise a different algorithm for deriving a one-state Minsky Machine from a multi-state Minsky Machine.

```javascript
const maxTapeIndexOf = (parsed) => {
  let max = undefined;

  for (const rules of parsed.slice(1)) {
    for (const [actionClause, guardClause] of rules) {
      for (const [tapeIndex] of actionClause.concat(guardClause)) {
        if (max === undefined || tapeIndex > max) max = tapeIndex;
      }
    }
  }

  return max;
};

const maxStateNumberOf = (parsed) => {
  return parsed.length - 1;
}

const NOOP = [1, 0];
const isNOOP = ([,squares]) => squares === 0;
const isActionable = ([,squares]) => squares !== 0;

const SUCCESS = [1, 0];
const isSuccess = ([,squares]) => squares === 0;
const canFail = ([,squares]) => squares !== 0;

const ruleCanFail = ([, guardClause]) => guardClause.every(canFail);

const withClause = (clauses, clause) => clauses.filter(canFail).concat([clause]);

export default (parsed) => {
  const maxTapeIndex = maxTapeIndexOf(parsed);
  const maxStateNumber = maxStateNumberOf(parsed);

  const stateToTape = new Map();

  for (let stateNumber = 2; stateNumber <= maxStateNumber; ++stateNumber) {
    const offset = maxTapeIndex + (2 * stateNumber) - 3;

    stateToTape.set(stateNumber, { stateIndex: offset, statePrimeIndex: offset + 1 });
  }

  const state1 = parsed[1];

  // adjust all rules in state 1 to set an emulated state
  // rather than use an explicit nextState if they point to
  // another state
  for (const rule of state1) {
    const [actionClause, guardClause, nextState] = rule;
    if (nextState > 1) {
      rule[0] = withClause(actionClause, [stateToTape.get(nextState).stateIndex, 1]);
      rule[2] = 1;
    }
  }

  let stateIndex = 1;
  let aggregateRules = [];
  for (const rules of parsed.slice(2)) {
    ++stateIndex;

    if (rules.every(ruleCanFail)) {
      // if we cannot guarantee action,
      // add an explicit fall-through to halt
      // this will get guarded below
      rules.push([[NOOP], [SUCCESS], 0]);
    }

    const stateEmulationGuard = [stateToTape.get(stateIndex).stateIndex, 1];

    for (const rule of rules) {
      const [actionClause, guardClause, nextState] = rule;

      if (nextState === stateIndex) {
        // this rule remains in the same state. we cannot directly
        // emulate the sate, because we are already guarding for it,
        // so we set the state-prime
        rule[0] = withClause(actionClause, [stateToTape.get(nextState).statePrimeIndex, 1]);
      } else if (nextState > 1) {
        // set an emulated state rather than use an explicit nextState
        // if nextState
        rule[0] = withClause(actionClause, [stateToTape.get(nextState).stateIndex, 1]);
      }

      rule[1] = withClause(guardClause, stateEmulationGuard);
      rule[2] = 1;
    }

    aggregateRules = aggregateRules.concat(rules); // TODO: refactor to flatMap

  }

  for (const { stateIndex, statePrimeIndex } of stateToTape.values()) {
    const actionClauses = [[stateIndex, 1]];
    const guardClauses = [[statePrimeIndex, 1]];

    aggregateRules.push([actionClauses, guardClauses, 1]);
  }

  aggregateRules = aggregateRules.concat(state1);

  return [[]].concat([aggregateRules]);
}
```

That is truly marvellous, but is it _meaningful_?

Yes, it is meaningful, and we're about to find out why.

---

## Notes

